{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56804aa5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b310dcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>N</th>\n",
       "      <th>i</th>\n",
       "      <th>d</th>\n",
       "      <th>K</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.196</td>\n",
       "      <td>4404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120</td>\n",
       "      <td>4404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102</td>\n",
       "      <td>4404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284</td>\n",
       "      <td>4404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075</td>\n",
       "      <td>4404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>0.402</td>\n",
       "      <td>4404</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>1.005</td>\n",
       "      <td>4404</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>0.853</td>\n",
       "      <td>4404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>1.482</td>\n",
       "      <td>4404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>0.061</td>\n",
       "      <td>4404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4404 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y     N  i  d  K  x\n",
       "0     0.196  4404  1  0  2  2\n",
       "1     0.120  4404  1  0  2  2\n",
       "2     0.102  4404  1  0  2  2\n",
       "3     0.284  4404  1  0  2  2\n",
       "4     0.075  4404  1  0  2  2\n",
       "...     ...   ... .. .. .. ..\n",
       "4399  0.402  4404  1  1  2  1\n",
       "4400  1.005  4404  1  1  2  1\n",
       "4401  0.853  4404  0  0  2  1\n",
       "4402  1.482  4404  0  0  2  1\n",
       "4403  0.061  4404  0  0  2  1\n",
       "\n",
       "[4404 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/stan_data_covariates.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db5006e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='y', ylabel='Count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 261,
       "width": 388
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebf5b5dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# stan_code = \"\"\"\n",
    "#         data {\n",
    "#             int<lower=0> N; // number of observations\n",
    "#             vector[N] y;    // observations (aggregated)\n",
    "#             vector[N] i;\n",
    "#             vector[N] d;\n",
    "#             int<lower=0> K; // number of groups (conditions)\n",
    "#             int<lower=1,upper=K> x[N]; // indicators for groups (conditions)\n",
    "#         }\n",
    "#         parameters {\n",
    "#             real<lower=0> alpha[K];        // pooled alpha (shape)\n",
    "#             real beta_0[K];\n",
    "#             real beta_i[K];\n",
    "#             real beta_d[K];\n",
    "#         }\n",
    "#         model {\n",
    "#             for (k in 1:K){\n",
    "#                 alpha[k] ~ normal(0, 10);\n",
    "#                 beta_0[k] ~ normal(0, 10);\n",
    "#                 beta_i[k] ~ normal(0, 10);\n",
    "#                 beta_d[k] ~ normal(0, 10);\n",
    "#             }\n",
    "\n",
    "#             for (n in 1:N){\n",
    "#                 y[n] ~ weibull(alpha[x[n]], exp(-(beta_0[x[n]] + beta_i[x[n]]*i[n] + beta_d[x[n]]*d[n])/alpha[x[n]]));  // likelihood / observation model\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#         generated quantities {\n",
    "#             vector[N] log_lik;\n",
    "#             vector[N] y_rep;\n",
    "#             int<lower = 0, upper = 1> mean_gt;\n",
    "#             int<lower = 0, upper = 1> sd_gt;\n",
    "#             for (n in 1:N){\n",
    "#                 log_lik[n] = weibull_lpdf(y[n] | alpha[x[n]], exp(-(beta_0[x[n]] + beta_i[x[n]]*i[n] + beta_d[x[n]]*d[n])/alpha[x[n]])); \n",
    "#                 y_rep[n] = weibull_rng(alpha[x[n]], exp(-(beta_0[x[n]] + beta_i[x[n]]*i[n] + beta_d[x[n]]*d[n])/alpha[x[n]]));\n",
    "#                 }\n",
    "#             mean_gt = mean(y_rep) > mean(y);\n",
    "#             sd_gt = sd(y_rep) > sd(y);\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8535d02e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#K = 2  # Number of condition\n",
    "# y[n] ~ weibull(alpha[x[n]], exp(-(beta_0[x[n]] + beta_i[x[n]]*i[n] + beta_d[x[n]]*d[n])/alpha[x[n]]));  // likelihood / observation model\n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a8069a2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_k = torch.nn.Parameter(torch.zeros(1))\n",
    "        self.log_lbda = torch.nn.Parameter(torch.zeros(1))\n",
    "#         self.mu_alpha = torch.nn.Parameter(torch.zeros(1))\n",
    "#         self.mu_beta_0 = torch.nn.Parameter(torch.zeros(1))\n",
    "#         self.mu_beta_i = torch.nn.Parameter(torch.zeros(1))\n",
    "#         self.mu_beta_d = torch.nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "#         self.logvar_alpha = torch.nn.Parameter(torch.zeros(1))\n",
    "#         self.logvar_beta_0 = torch.nn.Parameter(torch.zeros(1))\n",
    "#         self.logvar_beta_i = torch.nn.Parameter(torch.zeros(1))\n",
    "#         self.logvar_beta_d = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, i, d, y, n_sample=100):\n",
    "        \n",
    "#         eps = 1e-8\n",
    "        \n",
    "#         sd_alpha = torch.exp(0.5*self.logvar_alpha) + eps\n",
    "#         sd_beta_0 = torch.exp(0.5*self.logvar_beta_0) + eps\n",
    "#         sd_beta_i = torch.exp(0.5*self.logvar_beta_i) + eps\n",
    "#         sd_beta_d = torch.exp(0.5*self.logvar_beta_d) + eps\n",
    "        \n",
    "#         alpha = torch.randn(size=(n_sample, 1))*sd_alpha + self.mu_alpha\n",
    "#         beta_0 = torch.randn(size=(n_sample, 1))*sd_beta_0 + self.mu_beta_0\n",
    "#         beta_i = torch.randn(size=(n_sample, 1))*sd_beta_i + self.mu_beta_i\n",
    "#         beta_d = torch.randn(size=(n_sample, 1))*sd_beta_d + self.mu_beta_d\n",
    "        \n",
    "#         pen_alpha = torch.distributions.Normal(self.mu_alpha, sd_alpha).log_prob(alpha)\n",
    "#         pen_beta_0 = torch.distributions.Normal(self.mu_beta_0, sd_beta_0).log_prob(beta_0)\n",
    "#         pen_beta_i = torch.distributions.Normal(self.mu_beta_i, sd_beta_i).log_prob(beta_i)\n",
    "#         pen_beta_d = torch.distributions.Normal(self.mu_beta_d, sd_beta_d).log_prob(beta_d)\n",
    "        \n",
    "#         pen = pen_alpha + pen_beta_0 + pen_beta_i + pen_beta_d\n",
    "        \n",
    "#         k = torch.exp(alpha) + eps # alpha in Stan, k/shape in Wikipedia, k/contentration in Torch\n",
    "#         lbda = torch.exp(-(beta_0 + beta_i*i + beta_d*d) / k) # sigma in Stan, lambda/scale in Wikipdedia, scale in Torch\n",
    "        k = self.log_k.exp()  \n",
    "        lbda = self.log_lbda.exp()  \n",
    "        lls = torch.distributions.Weibull(concentration=k, scale=lbda).log_prob(y).sum()  # axis=-1\n",
    "        return - lls # + pen.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c988b085",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_k_mu = torch.nn.Parameter(torch.zeros(1))\n",
    "        self.log_k_logvar = torch.nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        self.log_lbda_mu = torch.nn.Parameter(torch.zeros(1))\n",
    "        self.log_lbda_logvar = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, i, d, y, n_sample=100):\n",
    "        \n",
    "        log_k_sd = torch.exp(0.5*self.log_k_logvar)\n",
    "        log_lbda_sd = torch.exp(0.5*self.log_lbda_logvar)\n",
    "        \n",
    "        log_k = torch.randn(size=(n_sample, 1))*log_k_sd + self.log_k_mu\n",
    "        log_lbda = torch.randn(size=(n_sample, 1))*log_lbda_sd + self.log_lbda_mu\n",
    "\n",
    "        pen_k = torch.distributions.Normal(self.log_k_mu, log_k_sd).log_prob(log_k)\n",
    "        pen_lbda = torch.distributions.Normal(self.log_lbda_mu, log_lbda_sd).log_prob(log_lbda)\n",
    "        \n",
    "        pen_mean = (pen_k + pen_lbda).mean()\n",
    "        \n",
    "        k = log_k.exp()\n",
    "        lbda = log_lbda.exp()\n",
    "        \n",
    "        lls = torch.distributions.Weibull(concentration=k, scale=lbda).log_prob(y).sum(axis=-1)\n",
    "        print(lls.shape)\n",
    "        mean_lls = lls.mean()\n",
    "        print(mean_lls, pen_mean)\n",
    "        return - mean_lls + pen_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fb42f05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, condition):\n",
    "\n",
    "        self.i, self.d, self.y = self.load_data(condition)\n",
    "\n",
    "    def load_data(self, condition):\n",
    "\n",
    "        df = pd.read_csv(\"data/stan_data_covariates.csv\", index_col=0)\n",
    "        df = df[df.x == condition]\n",
    "        i = torch.tensor(df.i.values, dtype=torch.float)\n",
    "        d = torch.tensor(df.d.values, dtype=torch.float)\n",
    "        y = torch.tensor(df.y.values, dtype=torch.float)\n",
    "\n",
    "        # y = torch.distributions.Weibull()\n",
    "\n",
    "        return i, d, y\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.i[idx], self.d[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b9c5179",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FakeDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, condition):\n",
    "\n",
    "        self.i, self.d, self.y = self.load_data(condition)\n",
    "\n",
    "    def load_data(self, condition):\n",
    "        n = 4000\n",
    "        k=0.90\n",
    "        lbda=1.04\n",
    "        y = torch.distributions.Weibull(concentration=k, scale=lbda).sample((n,))\n",
    "        \n",
    "        i = torch.zeros(n)\n",
    "        d = torch.zeros(n)\n",
    "\n",
    "        return i, d, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.i[idx], self.d[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a52f1355",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n observation 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–‰                                                                                           | 1/100 [00:00<00:06, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "tensor(-4.7050e+10, grad_fn=<MeanBackward0>) tensor(-2.9663, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Parameter of shape (1,)) of distribution Normal(loc: Parameter containing:\ntensor([nan], requires_grad=True), scale: tensor([nan], grad_fn=<ExpBackward0>)) to satisfy the constraint Real(), but found invalid values:\nParameter containing:\ntensor([nan], requires_grad=True)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [95]\u001B[0m, in \u001B[0;36m<cell line: 27>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(n_epochs)):\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch, (i, d, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[1;32m     29\u001B[0m         \u001B[38;5;66;03m# Compute prediction and loss\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m         loss \u001B[38;5;241m=\u001B[39m model(i, d, y)\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n\u001B[1;32m     33\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [92]\u001B[0m, in \u001B[0;36mModel.forward\u001B[0;34m(self, i, d, y, n_sample)\u001B[0m\n\u001B[1;32m     17\u001B[0m log_k \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(size\u001B[38;5;241m=\u001B[39m(n_sample, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m*\u001B[39mlog_k_sd \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_k_mu\n\u001B[1;32m     18\u001B[0m log_lbda \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(size\u001B[38;5;241m=\u001B[39m(n_sample, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m*\u001B[39mlog_lbda_sd \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_lbda_mu\n\u001B[0;32m---> 20\u001B[0m pen_k \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistributions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNormal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_k_mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_k_sd\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlog_prob(log_k)\n\u001B[1;32m     21\u001B[0m pen_lbda \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdistributions\u001B[38;5;241m.\u001B[39mNormal(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_lbda_mu, log_lbda_sd)\u001B[38;5;241m.\u001B[39mlog_prob(log_lbda)\n\u001B[1;32m     23\u001B[0m pen_mean \u001B[38;5;241m=\u001B[39m (pen_k \u001B[38;5;241m+\u001B[39m pen_lbda)\u001B[38;5;241m.\u001B[39mmean()\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/distributions/normal.py:54\u001B[0m, in \u001B[0;36mNormal.__init__\u001B[0;34m(self, loc, scale, validate_args)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     batch_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloc\u001B[38;5;241m.\u001B[39msize()\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mNormal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/distributions/distribution.py:55\u001B[0m, in \u001B[0;36mDistribution.__init__\u001B[0;34m(self, batch_shape, event_shape, validate_args)\u001B[0m\n\u001B[1;32m     53\u001B[0m         valid \u001B[38;5;241m=\u001B[39m constraint\u001B[38;5;241m.\u001B[39mcheck(value)\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m valid\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m---> 55\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     56\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     57\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(value\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     58\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof distribution \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     59\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto satisfy the constraint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(constraint)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     60\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut found invalid values:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     61\u001B[0m             )\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28msuper\u001B[39m(Distribution, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[0;31mValueError\u001B[0m: Expected parameter loc (Parameter of shape (1,)) of distribution Normal(loc: Parameter containing:\ntensor([nan], requires_grad=True), scale: tensor([nan], grad_fn=<ExpBackward0>)) to satisfy the constraint Real(), but found invalid values:\nParameter containing:\ntensor([nan], requires_grad=True)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "data = FakeDataset(condition=1)\n",
    "\n",
    "n_obs = len(data)\n",
    "print(\"n observation\", n_obs)\n",
    "\n",
    "# n_training = int(0.80*n_obs)\n",
    "# n_val = n_obs - n_training\n",
    "# training_data, val_data = torch.utils.data.random_split(data, [n_training, n_val])\n",
    "\n",
    "model = Model()\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=len(data))\n",
    "# val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=len(val_data))\n",
    "\n",
    "# for batch, (X, y) in enumerate(val_dataloader):\n",
    "\n",
    "#     pred = model(X)[:, 0]\n",
    "#     print(f\"Average abs error validation: {(pred - y).abs().mean():.2f}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=0.01, params=model.parameters())\n",
    "\n",
    "n_epochs = 100\n",
    "hist_loss = []\n",
    "\n",
    "for _ in tqdm(range(n_epochs)):\n",
    "    for batch, (i, d, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        loss = model(i, d, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        hist_loss.append(loss.item())\n",
    "\n",
    "# for batch, (X, y) in enumerate(dataloader):\n",
    "#     pred = model(X)[:, 0]\n",
    "#     unscaled_pred = data.unnormalize(pred, **data.y_kwargs_transform)\n",
    "#     unscaled_y = data.unnormalize(y, **data.y_kwargs_transform)\n",
    "#     print(torch.abs(unscaled_y - unscaled_pred))\n",
    "\n",
    "# for batch, (X, y) in enumerate(val_dataloader):\n",
    "#     pred = model(X)[:, 0]\n",
    "\n",
    "#     unscaled_pred = data.unnormalize(pred, **data.y_kwargs_transform)\n",
    "#     unscaled_y = data.unnormalize(y, **data.y_kwargs_transform)\n",
    "\n",
    "#     print(f\"Average abs error validation: {(unscaled_pred - unscaled_y).abs().mean():.2f}\")\n",
    "\n",
    "# os.makedirs(\"fig\", exist_ok=True)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"loss\")\n",
    "ax.plot(hist_loss)\n",
    "# plt.savefig(f\"fig/hist_loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46297154",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if isinstance(model, SimpleModel):\n",
    "    print(f\"k={model.log_k.exp().item():.2f} - lbda={model.log_lbda.exp().item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b30363a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=0.91 - lbda=1.05\n"
     ]
    }
   ],
   "source": [
    "print(f\"k={model.log_k_mu.exp().item():.2f} - lbda={model.log_lbda_mu.exp().item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614bd29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}